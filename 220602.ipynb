{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 22.06.02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Decision Tree 단점 보완\n",
    "    - 중간 node error 발생 시 다음 단계로 전파\n",
    "    - 데이터의 미세한 변동에 크게 영향받음\n",
    "    - depth 가 커지면 overfitting 가능성 높아짐"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ensemble\n",
    "    - 여러 모델의 예측을 통합하여 하나의 모델로 만듬(다수결, 평균 방법 사용)\n",
    "    - 여러 모델의 장점 결합\n",
    "    - Base 모델 독립, predict > 0.5  \n",
    "    - Random Forest 에서 다수의 DT를 ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Bagging (Boostrap Aggregating)\n",
    "    - random sampling with replacement\n",
    "    - 복원 추출로 원본 데이터와 같은 분포를 유지"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. K-means Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 각 군집에 할당 된 포인터들의 평균좌표를 이용해 중심점을 반복해서 업데이트\n",
    "    - k 개의 중심 좌표 생성\n",
    "    - 데이터를 가까운 중심 좌표로 군집\n",
    "    - 할당된 군집을 기반으로 새로운 중심 좌표 생성\n",
    "    - 모든 데이터의 군집이 바뀌지 않을때까지 반복"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
